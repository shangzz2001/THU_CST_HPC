# 奇偶排序实验报告

## 1. 实验源代码

> 代码的整体思路与作业给出的参考模型基本一致：
>
> - 进行进程内数组的排序
> - 奇偶相邻进程对进行奇偶排序

具体的实现将会在源代码中以注释的形式给出

```c++
// 获得一个 unsigned 值的数位值
inline unsigned getd(unsigned x, int d)
{
    return (x >> (d * 8)) & 255;
}
// 基数排序
inline void radix_sort(unsigned *start, int len)
{
    unsigned *b = new unsigned[sizeof(unsigned) * (len)];
    int cnt[256] = {0};
    for (int i = 0; i < 4; i++)
    {
        memset(cnt, 0, sizeof(cnt));
        for (int q = 0; q < len; q++)
            ++cnt[getd(start[q], i)];
        for (int q = 1; q <= 255; q++)
            cnt[q] += cnt[q - 1];
        if (i % 2 == 0)
            for (int q = len - 1; q >= 0; q--)
                b[--cnt[getd(start[q], i)]] = start[q];
        else
            for (int q = len - 1; q >= 0; q--)
                start[--cnt[getd(b[q], i)]] = b[q];
    }
    memcpy(b, start, sizeof(unsigned) * len);
    int beg = len - 1, q = beg;
    for (; (b[q] & 0x80000000) && (q >= 0); --q)
        start[beg - q] = b[q];
    memcpy(start + beg - q, b, sizeof(unsigned) * (q + 1));
    delete[] b;
    return;
}
// 如果当前进程作为进程对左进程时候的mergesort函数
void merge_left(float *other, int other_size, float *self, int self_size, float *buf)
{
    int i = 0, j = 0, k = 0;
    while (i < other_size && j < self_size)
    {
        if (other[i] < self[j])
        {
            buf[k++] = other[i++];
        }
        else
        {
            buf[k++] = self[j++];
        }
        if (k == self_size)
            return;
    }
    while (i < other_size)
    {
        buf[k++] = other[i++];
        if (k == self_size)
            return;
    }
    while (j < self_size)
    {
        buf[k++] = self[j++];
        if (k == self_size)
            return;
    }
}
// 如果当前进程作为进程对右进程时候的mergesort函数
void merge_right(float *other, int other_size, float *self, int self_size, float *buf)
{
    int i = other_size - 1, j = self_size - 1, k = self_size - 1;
    while (i >= 0 && j >= 0)
    {
        if (other[i] > self[j])
        {
            buf[k--] = other[i--];
        }
        else
        {
            buf[k--] = self[j--];
        }
        if (k == -1)
            return;
    }
    while (i >= 0)
    {
        buf[k--] = other[i--];
        if (k == -1)
            return;
    }
    while (j >= 0)
    {
        buf[k--] = self[j--];
        if (k == -1)
            return;
    }
}
void Worker::sort()
{
    /** Your code ... */
    // you can use variables in class Worker: n, nprocs, rank, block_len, data
  	// 当 block len 不大于 500 时，使用基本的 sort函数，否则使用基数排序
    if (out_of_range)
        return;
    if (block_len <= 500)
        std::sort(data, data + block_len);
    else
        radix_sort((unsigned *)data, block_len);
    if (nprocs == 1)
        return;
  	// 计算每一轮运算相邻进程的相关信息
    int neighborindex[2];
    size_t block_size = ceiling(n, nprocs);
    size_t neighborblocklen[2];
    bool isright[2];
    bool skip[2] = {false, false}; // 是否处于边界位置可以直接跳跃
    float *recv_buf = new float[block_size]; // 接收缓存区
    float *my_merge_result = new float[block_len]; 
    MPI_Request request[2];
    for (int round = 0; round < 2; round++)
    {
        // 计算奇偶轮运算相邻进程的相关信息
        //  是否处于边界位置可以直接跳跃
        if (round == 0 && last_rank && nprocs % 2 == 1)
        {
            skip[0] = true;
        }
        if (round == 1 && (rank == 0 || (nprocs % 2 == 0 && last_rank)))
        {
            skip[1] = true;
        }
        // 是否为进程对中的右进程
        isright[round] = (round % 2 == 0) == (rank % 2 == 1);
        // 计算相邻数据块
        neighborindex[round] = isright[round] ? rank - 1 : rank + 1;
        if (neighborindex[round] < 0 || neighborindex[round] >= nprocs)
            continue;
        // 计算相邻数据块的大小
        neighborblocklen[round] = std::min(block_size, n - block_size * neighborindex[round]);
    }
  // 进行 nprocs 轮循环
   for (int i = 0; i < nprocs; i++)
    {
        int idx = i % 2;
        if (skip[idx])
            continue;
       // 向相邻进程发送数据
        MPI_Isend(data, block_len, MPI_FLOAT, neighborindex[idx], 0, MPI_COMM_WORLD, request + 0);
        MPI_Irecv(recv_buf, neighborblocklen[idx], MPI_FLOAT, neighborindex[idx], 0, MPI_COMM_WORLD, request + 1);
        if (!isright[idx])
        {
            MPI_Wait(&request[1], nullptr);
          // 判断是否需要进行归并排序
            if (data[block_len - 1] > recv_buf[0])
            {
                merge_left(recv_buf, neighborblocklen[idx], data, block_len, my_merge_result);
                MPI_Wait(&request[0], nullptr);
                std::swap(data, my_merge_result);
            }
            else
            {
                MPI_Wait(&request[0], nullptr);
            }
        }
        else
        {
            MPI_Wait(&request[1], nullptr);
            // 判断是否需要进行归并排序
            if (data[0] < recv_buf[neighborblocklen[idx] - 1])
            {
                merge_right(recv_buf, neighborblocklen[idx], data, block_len, my_merge_result);
                MPI_Wait(&request[0], nullptr);
                std::swap(data, my_merge_result);
            }
          // 不需要则直接返回即可
            else
            {
                MPI_Wait(&request[0], nullptr);
            }
        }
    }
    delete[] my_merge_result;
    delete[] recv_buf;
}

```

## 2. 性能优化尝试

- 有关整体有序性的额外判断

  起初我对数据块是否已经有序进行了额外的排查，每一轮需要额外花费一次通信的时间成本判断是否全部都是有序的，后来觉得时间成本过大删除。

  优化思路是删除额外的通信排查操作，固定循环 $nprocs$ 轮，经过这些循环后必然是有序的

- 归并排序

  进程对的两个进程都互相向对方发送自己的数据，然后根据自己所在的位置：左或者右，进行相应部分的归并排序即可。起初我设置了一个主程序进行归并排序然后将归并结果发送给子程序，时间成本会更高，这样优化也可以节省一次通信时间。

- 归并操作必要性判断

  不过针对每两个子进程的归并排序进行了必要性判断，如果左数据段的最后一个元素小于右数据段的最后一个元素，则无需进行归并排序

- 基础排序算法的优化

  本次实验起初使用了基本的 std:: sort ，后来选择了时间复杂度更低的基数排序算法，如此在大规模数据的排序中可以获得更好的实验效果。

## 实验结果

| $N\times P$  | 1 X 1    | 1 X 2    | 1 X 4    | 1 X 8   | 1 X 16  | 2 X 16  |
| ------------ | -------- | -------- | -------- | ------- | ------- | ------- |
| 耗费时间(ms) | 3321.816 | 2042.373 | 1424.453 | 910.119 | 699.890 | 537.630 |
| 加速比       | 1        | 1.6264   | 2.3320   | 3.6499  | 4.7462  | 6.1786  |

